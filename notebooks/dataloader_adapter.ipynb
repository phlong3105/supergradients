{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset Adapter\n",
    "\n",
    "With diverse dataset structures available, ensuring compatibility with SuperGradients (SG) can be challenging. This is where the DataloaderAdapter plays a pivotal role. This tutorial takes you through the importance, implementation, and advantages of using the DataloaderAdapter with SG."
   ],
   "metadata": {
    "id": "maykjDsh7d2x",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Why Dataset Adapter?\n",
    "\n",
    "Datasets come in a myriad of structures. However, SG requires data in a specific format.\n",
    "\n",
    "For instance, consider the Object Detection Format:\n",
    "\n",
    "Image format should be: (BS, H, W, C) i.e., channel last.\n",
    "Targets should be in the format: (BS, 6), where 6 represents (sample_id, class_id, label, cx, cy, w, h).\n",
    "The overhead of adjusting each dataset manually can be cumbersome. Enter DataloaderAdapter â€“ designed to automatically understand your dataset structure and mold it for SG compatibility."
   ],
   "metadata": {
    "id": "rYLVw---7mgu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q super-gradients==3.7.1"
   ],
   "metadata": {
    "id": "0puCRQGZSP8r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f244cb86-c7e5-419b-f0e1-f0807aac017d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Why Do We Need the Dataset Adapter?\n",
    "\n",
    "While Datasets come in various structures and formats, SG expects data in a specific format to be able to run.\n",
    "\n",
    "\n",
    "> Example: Object Detection Format\n",
    "> - Image format: (BS, H, W, C) i.e. channel last\n",
    "> - Targets format: (BS, 6) where 6 represents (sample_id, class_id, label, cx, > cy, w, h).\n",
    "\n",
    "\n",
    "This means that you should either use one of SuperGradient's built-in Dataset class if it supports your dataset structure, or, if your dataset is too custom for it, inherit from SG datasets and bring all the required changes.\n",
    "\n",
    "While this is all right in most cases, it can be cumbersome when you just want to quickly experiment with a new dataset.\n",
    "\n",
    "To reduce this overhead, SuperGradients introduced the concept of `DataloaderAdapter`. Instead of requiring you to write all the transformations required to use SG, the `DataloaderAdapter` will infer anything possible directly from your data. Whenever something cannot be inferred with 100% confidence, you will be asked a question with all the required context for you to properly answer.\n",
    "\n",
    "Let's see this in practice with an example. Let's start with `SBDataset` dataset"
   ],
   "metadata": {
    "id": "VWKtR3sOfRuB",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exemple 1 - Segmentation Adapter on `SBDataset` Dataset\n",
    "\n",
    "In this section, we'll walk through the process of preparing the `SBDataset` dataset for use in SuperGradients. We'll highlight the challenges and demonstrate how the Adapter can simplify the process.\n",
    "\n",
    "\n",
    "1. Preparing the Dataset without Adapter"
   ],
   "metadata": {
    "id": "dvbJpo5Z7w6n",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import SBDataset\n",
    "\n",
    "try:\n",
    "  # There is a bug with `torchvision.datasets.SBDataset` that raises RuntimeError after downloading, so we just ignore it\n",
    "  SBDataset(root=\"data\", mode='segmentation', download=True)\n",
    "except RuntimeError:\n",
    "  pass"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHg2-CiFTcx9",
    "outputId": "4043dee7-29c5-40aa-d2ad-0a10fc4fd1c6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oGHI8LgZSIiz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Resize, InterpolationMode\n",
    "\n",
    "\n",
    "transforms = Compose([ToTensor(), Resize((512, 512), InterpolationMode.NEAREST)])\n",
    "def sample_transform(image, mask):\n",
    "  return transforms(image), transforms(mask)\n",
    "\n",
    "train_set = SBDataset(root=\"data\", mode='segmentation', download=False, transforms=sample_transform)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's see what we get when instantiating a `Dataloader`"
   ],
   "metadata": {
    "id": "SEuJd57v8ELj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=20, shuffle=True)\n",
    "_images, labels = next(iter(train_loader))\n",
    "\n",
    "labels.unique()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnJJNCSr8DUW",
    "outputId": "1f4fb2a5-fbe1-4604-ce6c-ff85079c9180",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, the labels are normalized (0-1). This is all right, but it is not the format expected by SuperGradients.\n",
    "\n",
    "Let's now see how the Adapter helps.\n",
    "\n",
    "2. Introducing Adapter\n",
    "\n",
    "The Adapter helps us skip manual data preparations and dives right into creating a dataloader that SuperGradients expects."
   ],
   "metadata": {
    "id": "Ex4-AmV474Nl",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from super_gradients.training.dataloaders.adapters import SegmentationDataloaderAdapterFactory\n",
    "\n",
    "train_loader = SegmentationDataloaderAdapterFactory.from_dataset(dataset=train_set, batch_size=20, shuffle=True, config_path='cache_file.json')\n",
    "\n",
    "_images, labels = next(iter(train_loader))\n",
    "labels.unique()"
   ],
   "metadata": {
    "id": "BVDBTQd_FZMe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9ac4683d-25ed-427a-cba0-e132f10bea77",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that the mask is now encoded as `int`, which is the representation used in SuperGradients.\n",
    "\n",
    "It's important to note that the dataset adapter also support different dataset format such as one hot, ensuring that the output (`labels` here) is in the right format to use within SuperGradients."
   ],
   "metadata": {
    "id": "yMnGHW1kCO2h",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example II - Detection Adapter on a Dictionary based Dataset\n",
    "\n",
    "Some datasets return a more complex data structure than the previous example.\n",
    "\n",
    "For instance, the `COCO` dataset implementation from `pytorch` returns a list of dictionaries representing the labels.\n",
    "\n",
    "Let's have a look:\n"
   ],
   "metadata": {
    "id": "-sEjb4d6jqIK",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download the zip file\n",
    "!wget https://deci-pretrained-models.s3.amazonaws.com/coco2017_small.zip\n",
    "\n",
    "# Unzip the downloaded file\n",
    "!unzip coco2017_small.zip > /dev/null"
   ],
   "metadata": {
    "id": "7nb2DFNhbHff",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aaf48023-dc04-4f72-9318-ffa15f5eb6b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import Compose, ToTensor, Resize, InterpolationMode\n",
    "from torchvision.datasets import SBDataset\n",
    "\n",
    "\n",
    "image_transform = Compose([ToTensor(), Resize((512, 512))])\n",
    "\n",
    "train_set = CocoDetection(root='coco2017_small/images/train2017', annFile='coco2017_small/annotations/instances_train2017.json', transform=image_transform)\n",
    "val_set = CocoDetection(root='coco2017_small/images/val2017', annFile='coco2017_small/annotations/instances_val2017.json', transform=image_transform)\n",
    "image, targets = next(iter(train_set))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8ox8EbVbxVU",
    "outputId": "72cf85a5-e143-436d-9d0e-12ce2e8d8742",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Number of targets: {len(targets)}, First target structure: {targets[0]}\")"
   ],
   "metadata": {
    "id": "BhuJfMHM9g-a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observe the dataset output's nested dictionary structure? This complicates things for the Dataset Adapter as it's unsure which fields detail the bounding box.\n",
    "\n",
    "To solve this, we utilize an extractor function.\n",
    "\n",
    "#### The Extractor's Role\n",
    "\n",
    "Simply put, the extractor translates your dataset's output into a format the Adapter understands. For our dataset, it will take the image and annotations, then return the bounding box data, including the label and coordinates.\n",
    "\n",
    "Worried about bounding box format like `xyxy_label` or `label_xywh`? Don't be. The Adapter is designed to recognize them.\n",
    "\n",
    "> For further guidance on extractor functions, see the [official documentation](https://github.com/Deci-AI/data-gradients/blob/master/documentation/dataset_extractors.md)."
   ],
   "metadata": {
    "id": "VKWqK2OwdbS9",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def coco_labels_extractor(sample) -> torch.Tensor:\n",
    "    _, annotations = sample # annotations = [{\"bbox\": [1.08, 187.69, 611.59, 285.84], \"category_id\": 51}, ...]\n",
    "    labels = []\n",
    "    for annotation in annotations:\n",
    "        class_id = annotation[\"category_id\"]\n",
    "        bbox = annotation[\"bbox\"]\n",
    "        labels.append((class_id, *bbox))\n",
    "    return torch.Tensor(labels) # torch.Tensor([[51, 1.08, 187.69, 611.59, 285.84], ...])\n",
    "\n",
    "coco_labels_extractor(sample=next(iter(train_set)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkmopVSocq9e",
    "outputId": "e51572d9-e066-4639-e02b-3cc5ea5da167",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This output is all you need to get started. Now we can use the Dataloader Adapters!"
   ],
   "metadata": {
    "id": "vz97TRpZj451",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from super_gradients.training.dataloaders.adapters import DetectionDataloaderAdapterFactory\n",
    "from data_gradients.dataset_adapters.config.data_config import DetectionDataConfig\n",
    "\n",
    "\n",
    "adapter_config = DetectionDataConfig(labels_extractor=coco_labels_extractor, cache_path=\"coco_adapter_cache.json\")\n",
    "train_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cOJAT81ZfhO",
    "outputId": "578a4746-7bef-4189-d9e6-b92ccbec6b94",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "_image, targets = next(iter(train_loader))\n",
    "targets.shape # [N, 6] format with 6 representing (sample_id, class_id, cx, cy, w, h)"
   ],
   "metadata": {
    "id": "m1S8n5YzgOKM",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "8749f639-78e3-4d20-cb5b-fa449ba9e0c8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Use your Adapted Dataloader to train a model"
   ],
   "metadata": {
    "id": "k6mRrkgF_zL7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have an adapter for a detection dataset, let's use it to launch a training of YoloNAS on it!\n",
    "\n",
    "This is of course for the sake of the example, since YoloNAS was originally trained using the SuperGradients implementation of COCO Dataset. You can replace the `COCO` dataset with any of your dataset."
   ],
   "metadata": {
    "id": "_B5WQlBwgjdu",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from super_gradients import Trainer\n",
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "from super_gradients.training import training_hyperparams\n",
    "from super_gradients.common.environment.cfg_utils import load_recipe\n",
    "\n",
    "\n",
    "trainer = Trainer(experiment_name=\"yolonas_training_with_adapter\", ckpt_root_dir=\"./\")\n",
    "model = models.get(model_name=Models.YOLO_NAS_S, num_classes=adapter_config.n_classes, pretrained_weights=\"coco\")\n",
    "\n",
    "yolonas_recipe = load_recipe(config_name=\"coco2017_yolo_nas_s\", overrides=[f\"arch_params.num_classes={adapter_config.n_classes}\", \"training_hyperparams.max_epochs=1\", \"training_hyperparams.mixed_precision=False\"])\n",
    "yolonas_recipe = OmegaConf.to_container(instantiate(yolonas_recipe))\n",
    "training_params = yolonas_recipe['training_hyperparams']\n",
    "\n",
    "trainer.train(model=model, training_params=training_params, train_loader=train_loader, valid_loader=val_loader)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKvvqGvQC_k0",
    "outputId": "a9c90ec9-8ebb-492a-d2ca-31b9490ff7b3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IV. Dig deeper into the Adapter\n",
    "\n",
    "By default, any parameter that could not be confidently infered will trigger a question.\n",
    "\n",
    "But you have the possibility to set these parameters in advance through the config object. In the previous example we had to set `labels_extractor` explicitly. Now let's set all the parameters"
   ],
   "metadata": {
    "id": "JWUsWehVmowy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from super_gradients.training.dataloaders.adapters import DetectionDataloaderAdapterFactory\n",
    "from data_gradients.dataset_adapters.config.data_config import DetectionDataConfig\n",
    "from data_gradients.utils.data_classes.image_channels import ImageChannels\n",
    "class_names = [category['name'] for category in train_set.coco.loadCats(train_set.coco.getCatIds())]\n",
    "\n",
    "adapter_config = DetectionDataConfig(\n",
    "    labels_extractor=coco_labels_extractor,\n",
    "    is_label_first=True,\n",
    "    class_names=class_names,\n",
    "    image_channels=ImageChannels.from_str(\"RGB\"),\n",
    "    xyxy_converter='xywh',\n",
    "    cache_path=\"coco_adapter_cache_with_default.json\"\n",
    ")"
   ],
   "metadata": {
    "id": "wsV8JpBJmyIH",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "3b963871-663a-4155-cfc3-7654fbd7f255",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "This can now be used and you don't need to answer any question"
   ],
   "metadata": {
    "id": "__YWkBVas6Yp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "_image, targets = next(iter(train_loader))\n",
    "targets.shape # [N, 6] format with 6 representing (sample_id, class_id, cx, cy, w, h)"
   ],
   "metadata": {
    "id": "uZDZg14InB3U",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7fc801c7-abac-4319-ad68-afef23e6df29",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load from existing cache\n",
    "\n",
    "You can use the cache of an adapter you already used in the past. This will allow you skip the questions that were already asked in the previous run."
   ],
   "metadata": {
    "id": "otTI_sVxtxvf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# The new config will load the answer from questions asked in the previous run.\n",
    "adapter_config = DetectionDataConfig(\n",
    "    labels_extractor=coco_labels_extractor,\n",
    "    cache_path=\"coco_adapter_cache_with_default.json\" # Name of the previous cache\n",
    ")\n",
    "\n",
    "train_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DetectionDataloaderAdapterFactory.from_dataset(\n",
    "    dataset=train_set,\n",
    "    config=adapter_config,\n",
    "    batch_size=5,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "_image, targets = next(iter(train_loader))"
   ],
   "metadata": {
    "id": "y3I00k-2svd3",
    "pycharm": {
     "name": "#%%\n"
    },
    "outputId": "3c5bd8b4-3781-4657-d0ef-a40e896c6a4a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "targets.shape # [N, 6] format with 6 representing (sample_id, class_id, cx, cy, w, h)"
   ],
   "metadata": {
    "id": "988EZEJpU3bf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d6bfd31b-5b86-4d3a-b2b9-94bb4f40b52f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, no question was asked and we still get the targets adapted into the SuperGradients format."
   ],
   "metadata": {
    "id": "1Fw4yhwkuK7w",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}
